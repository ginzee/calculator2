{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"0\" style=\"width:100%\">\n",
    " <tr>\n",
    "    <td>\n",
    "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/c/ce/IE_University_logo.svg\" width=150>\n",
    "     </td>\n",
    "    <td><div style=\"font-family:'Courier New'\">\n",
    "            <div style=\"font-size:25px\">\n",
    "                <div style=\"text-align: right\"> \n",
    "                    <b> MASTER IN BIG DATA</b>\n",
    "                    <br>\n",
    "                    Python for Data Analysis II\n",
    "                    <br><br>\n",
    "                    <em> Daniel Sierra Ramos </em>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </td>\n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unit Testing with `pytest`**\n",
    "\n",
    "## Overview\n",
    "\n",
    "Testing is a critical process in software development that helps verify that code works as intended and catches potential issues early. There are several main types of testing:\n",
    "\n",
    "1. **Unit Testing**: Tests individual components/functions in isolation\n",
    "2. **Integration Testing**: Tests how multiple components work together\n",
    "3. **System Testing**: Tests the complete, integrated system\n",
    "4. **Acceptance Testing**: Validates if the system meets business requirements\n",
    "5. More: security tests, performance tests, etc.\n",
    "\n",
    "Each type serves a specific purpose in ensuring overall software quality. In this session, we'll focus on **unit testing**, which forms the foundation of the testing pyramid.\n",
    "\n",
    "**Unit testing** is a fundamental practice in software development that helps ensure code reliability and maintainability. In this session, we'll learn about unit testing in Python using the pytest framework, which is known for its simplicity and powerful features.\n",
    "\n",
    "**Note: While we'll be using a Jupyter notebook for learning purposes, real unit tests are typically written in separate .py files in your project's test directory.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Unit Testing\n",
    "\n",
    "Unit testing is the practice of testing individual components or **units of code in isolation**. A unit test typically follows this pattern:\n",
    "\n",
    "Let's start by installing pytest:\n",
    "\n",
    "```bash\n",
    "pip install pytest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic Test Structure\n",
    "\n",
    "Let's write our first test. We'll start with a simple function and its corresponding test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def test_add_numbers():\n",
    "    # Arrange\n",
    "    a, b = 2, 3\n",
    "    expected = 5\n",
    "    \n",
    "    # Act\n",
    "    result = add_numbers(a, b)\n",
    "    \n",
    "    # Assert\n",
    "    assert result == expected, f\"Expected {expected}, but got {result}\"\n",
    "\n",
    "# Run the test\n",
    "test_add_numbers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSERT IS THE PYTEST LIBRARY\n",
    "- IF IT FAILS, IT RAISES AN EXCEPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF YOU HAVE MULTIPLE CASE SCENARIOS YOU WANT TO TEST, YOU CREATE MULTIPLE TESTS\n",
    "- IT'S NOT GOOD PRACTICE TO SET PARAMETERS INSIDE YOUR TEST FUNCTION. DON'T DO TEST_FUNCTION(A,B):, RATHER TEST_FUNCTION(): AND THEN A =, B = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the test passes, nothing happens. But, what happen if the test fails?\n",
    "\n",
    "Let's build the `add_numbers` function in a wrong way, on purpose, to see what happens when the test fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Expected 5, but got 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;241m==\u001b[39m expected, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m test_add_numbers()\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36mtest_add_numbers\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m result \u001b[38;5;241m=\u001b[39m add_numbers(a, b)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Assert\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;241m==\u001b[39m expected, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Expected 5, but got 6"
     ]
    }
   ],
   "source": [
    "# wrong function to add numbers\n",
    "def add_numbers(a, b):\n",
    "    return a + b + 1\n",
    "\n",
    "def test_add_numbers():\n",
    "    # Arrange\n",
    "    a, b = 2, 3\n",
    "    expected = 5\n",
    "    \n",
    "    # Act\n",
    "    result = add_numbers(a, b)\n",
    "    \n",
    "    # Assert\n",
    "    assert result == expected, f\"Expected {expected}, but got {result}\"\n",
    "\n",
    "# Run the test\n",
    "test_add_numbers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Write Your First Test\n",
    "\n",
    "Write a function `multiply_numbers(a, b)` and its corresponding test function `test_multiply_numbers()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def multiply_numbers(a, b):\n",
    "    pass  # Replace with your implementation\n",
    "\n",
    "def test_multiply_numbers():\n",
    "    pass  # Write your test here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Multiple assertions\n",
    "\n",
    "pytest provides rich assertion introspection. When an assertion fails, pytest shows detailed information about what went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rectangle_area(width, height):\n",
    "    return width * height\n",
    "\n",
    "def test_rectangle_area():\n",
    "    # Test with positive numbers\n",
    "    assert calculate_rectangle_area(4, 5) == 20\n",
    "    \n",
    "    # Test with zero\n",
    "    assert calculate_rectangle_area(0, 5) == 0\n",
    "    \n",
    "    # Test with floating point numbers\n",
    "    assert calculate_rectangle_area(2.5, 3.0) == 7.5\n",
    "\n",
    "test_rectangle_area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Testing with Multiple Assertions\n",
    "\n",
    "Write a function `is_palindrome(text)` that checks if a string is a palindrome, and write tests for it with multiple assertions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_palindrome(text):\n",
    "    return text == text[::-1]\n",
    "\n",
    "def test_is_palindrome():\n",
    "    pass  # Your tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Testing Exceptions\n",
    "\n",
    "Sometimes we need to test if our code raises the correct exceptions in error cases. pytest provides a convenient way to test for exceptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def divide_numbers(a, b):\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "\n",
    "def test_divide_numbers():\n",
    "    # Test normal division\n",
    "    assert divide_numbers(10, 2) == 5\n",
    "    \n",
    "    # Test division by zero\n",
    "    with pytest.raises(ValueError):\n",
    "        divide_numbers(10, 0)\n",
    "\n",
    "test_divide_numbers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Testing Exceptions\n",
    "\n",
    "Write a function `get_element(lst, index)` that returns the element at the given index from a list. The function should raise appropriate exceptions for invalid inputs. Write tests for both valid and invalid cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(lst, index):\n",
    "    if type(lst) != list:\n",
    "        raise TypeError(\"Input must be a list\")\n",
    "    if type(index) != int:\n",
    "        raise TypeError(\"Index must be an integer\")\n",
    "    if index < 0 or index >= len(lst):\n",
    "        raise IndexError(\"Index out of range\")\n",
    "    return lst[index]\n",
    "\n",
    "def test_get_element():\n",
    "    pass  # Your tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grouping Test Cases\n",
    " \n",
    "When you have multiple related tests, it's often helpful to group them together in a **test class**. This helps organize your tests and makes it easier to run them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we havetwo classes representing a `Calculator` and a `ScientificCalculator`. Each class contains several methods corresponding with the typical functionality of a calculator (basic or scientific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator:\n",
    "    \"\"\"A basic calculator with standard arithmetic operations.\"\"\"\n",
    "    \n",
    "    def add(self, a, b):\n",
    "        \"\"\"Add two numbers.\"\"\"\n",
    "        return a + b\n",
    "        \n",
    "    def subtract(self, a, b):\n",
    "        \"\"\"Subtract b from a.\"\"\"\n",
    "        return a - b\n",
    "    \n",
    "class ScientificCalculator(Calculator):\n",
    "    \"\"\"A scientific calculator that extends the basic Calculator.\"\"\"\n",
    "    \n",
    "    def power(self, base, exponent):\n",
    "        \"\"\"Calculate base raised to the exponent.\"\"\"\n",
    "        return base ** exponent\n",
    "    \n",
    "    def square_root(self, number):\n",
    "        \"\"\"Calculate the square root of a number.\"\"\"\n",
    "        if number < 0:\n",
    "            raise ValueError(\"Cannot calculate square root of negative number\")\n",
    "        return number ** 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a test suite for these classes by grouping related tests in a class: the ``TestCalculator`` class and the ``TestScientificCalculator`` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCalculator:\n",
    "    \"\"\"Tests for the Calculator class.\"\"\"\n",
    "    \n",
    "    def test_add(self):\n",
    "        calc = Calculator()\n",
    "        assert calc.add(2, 3) == 5\n",
    "        assert calc.add(-1, 1) == 0\n",
    "        assert calc.add(0, 0) == 0\n",
    "    \n",
    "    def test_subtract(self):\n",
    "        calc = Calculator()\n",
    "        assert calc.subtract(5, 3) == 2\n",
    "        assert calc.subtract(1, 1) == 0\n",
    "        assert calc.subtract(0, 5) == -5\n",
    "\n",
    "class TestScientificCalculator:\n",
    "    \"\"\"Tests for the ScientificCalculator class.\"\"\"\n",
    "    \n",
    "    def test_power(self):\n",
    "        calc = ScientificCalculator()\n",
    "        assert calc.power(2, 3) == 8\n",
    "        assert calc.power(5, 0) == 1\n",
    "        assert calc.power(2, -1) == 0.5\n",
    "    \n",
    "    def test_square_root(self):\n",
    "        calc = ScientificCalculator()\n",
    "        assert calc.square_root(9) == 3\n",
    "        assert calc.square_root(0) == 0\n",
    "        assert calc.square_root(2) == pytest.approx(1.4142, rel=1e-4)\n",
    "\n",
    "    def test_square_root_negative(self):\n",
    "        calc = ScientificCalculator()\n",
    "        with pytest.raises(ValueError):\n",
    "            calc.square_root(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can execute the tests just by executing the testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pytest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m test_scalc \u001b[38;5;241m=\u001b[39m TestScientificCalculator()\n\u001b[1;32m      8\u001b[0m test_scalc\u001b[38;5;241m.\u001b[39mtest_power() \n\u001b[0;32m----> 9\u001b[0m test_scalc\u001b[38;5;241m.\u001b[39mtest_square_root()\n\u001b[1;32m     10\u001b[0m test_scalc\u001b[38;5;241m.\u001b[39mtest_square_root_negative()\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mTestScientificCalculator.test_square_root\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m calc\u001b[38;5;241m.\u001b[39msquare_root(\u001b[38;5;241m9\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m calc\u001b[38;5;241m.\u001b[39msquare_root(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m calc\u001b[38;5;241m.\u001b[39msquare_root(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m==\u001b[39m pytest\u001b[38;5;241m.\u001b[39mapprox(\u001b[38;5;241m1.4142\u001b[39m, rel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pytest' is not defined"
     ]
    }
   ],
   "source": [
    "# Run calculator tests\n",
    "test_calc = TestCalculator()\n",
    "test_calc.test_add()\n",
    "test_calc.test_subtract()   \n",
    "\n",
    "# Run scientific calculator tests\n",
    "test_scalc = TestScientificCalculator()\n",
    "test_scalc.test_power() \n",
    "test_scalc.test_square_root()\n",
    "test_scalc.test_square_root_negative()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Executing unit tests in real code\n",
    "\n",
    "### 3.1 The `pytest` command\n",
    "\n",
    "Tests are not typically run in Jupyter notebooks. Instead, you would run them from the command line using the `pytest` command. To run all tests in a directory, you can simply run:\n",
    "\n",
    "```bash \n",
    "pytest\n",
    "``` \n",
    "\n",
    "To run tests in a specific file, you can run:\n",
    "\n",
    "```bash \n",
    "pytest test_file.py\n",
    "```\n",
    "\n",
    "To run a specific test function, you can run:\n",
    "\n",
    "```bash\n",
    "pytest test_file.py::test_function\n",
    "```\n",
    "\n",
    "Let's do it with our calculators example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE WE JUST TALK ABOUT HOW WE TEST THINGS IN TERMINAL, NOT IN A JUPYTER NOTEBOOK. FIRST WE DEVELOP A TEST FILE, AND THEN WE INITIATE THE TEST FILE VIA THE CODE ABOVE. \n",
    "- if you want more detail... add '-v' before you run the test file.. it'll tell you all the tests taht passed one by one. and the ones that failed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Assesing the testing coverage\n",
    "\n",
    "The testing coverage is a metric that shows the percentage of your code that is covered by tests. A high coverage percentage indicates that most of your code is tested, which can help ensure its reliability. `pytest-cov` is a plugin for pytest that generates coverage reports. To use it, you need to install it:\n",
    "\n",
    "```bash\n",
    "pip install pytest-cov\n",
    "```\n",
    "\n",
    "Then, you can run pytest with coverage:\n",
    "\n",
    "```bash\n",
    "pytest --cov\n",
    "```\n",
    "\n",
    "This will generate a coverage report showing which parts of your code are covered by tests.\n",
    "\n",
    "Also, you can generate an HTML report with the following command:\n",
    "\n",
    "```bash \n",
    "pytest --cov --cov-report=html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASICALLY TELLS YOU IF YOUR TEST FILE TESTS EVERYTHING IN YOUR FUNCTION/LIBRARY FILE. IT DISPLAYS THE TESTS AS A PERCENTAGE OF THE WHOLE. \n",
    "- THE HTML REPORT TELLS YOU WHICH FUNCTIONS YOU ARE AND ARE NOT TESTING. \n",
    "- YOU DONT NEED TO PLUG IN THE NAMES OF THE FILES YOU ARE COVERING. IT IS AUTOMATIC BECUASE YOU RUN IT INSIDE THE FILE THAT CONTAINS THE LIBRARY AND TEST FILE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Best Practices for Unit Testing\n",
    "\n",
    "1. **Test Isolation**: Each test should be independent and not rely on other tests\n",
    "2. **Clear Names**: Use descriptive names for test functions that indicate what's being tested\n",
    "3. **Single Responsibility**: Each test should verify one specific behavior\n",
    "4. **Test Edge Cases**: Include tests for boundary conditions and error cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
